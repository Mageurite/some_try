#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆå»¶è¿Ÿæµ‹è¯•è„šæœ¬
ä»…æµ‹è¯•LLMçš„First Tokenå»¶è¿Ÿï¼Œä¸éœ€è¦WebRTCä¾èµ–
"""

import time
import json
import requests
from datetime import datetime

def print_header(title):
    """æ‰“å°æµ‹è¯•æ ‡é¢˜"""
    print("\n" + "="*60)
    print(f"  {title}")
    print("="*60)

def print_result(name, value, unit="ms"):
    """æ‰“å°æµ‹è¯•ç»“æœ"""
    if unit == "ms":
        print(f"  âœ… {name}: {value*1000:.2f} {unit}")
    else:
        print(f"  âœ… {name}: {value:.4f} {unit}")

def test_llm_first_token_latency(test_text="Hello, how are you?", llm_url="http://localhost:8610/chat/stream"):
    """æµ‹è¯•LLMçš„First Tokenå»¶è¿Ÿ"""
    print_header("LLM First Tokenå»¶è¿Ÿæµ‹è¯•")
    
    try:
        print(f"  ğŸ“ æµ‹è¯•æ–‡æœ¬: '{test_text}'")
        print(f"  ğŸ”— LLMæœåŠ¡: {llm_url}")
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # å‘é€è¯·æ±‚
        response = requests.post(
            llm_url,
            json={
                "input": test_text,
                "session_id": 999999,
                "user_id": 1
            },
            stream=True,
            timeout=60
        )
        
        request_sent_time = time.time()
        
        if response.status_code != 200:
            raise Exception(f"LLMæœåŠ¡è¿”å›é”™è¯¯: {response.status_code}")
        
        print(f"  â³ ç­‰å¾…å“åº”...\n")
        
        # è¯»å–æµå¼å“åº”
        first_chunk_time = None
        last_chunk_time = None
        chunk_count = 0
        total_chars = 0
        chunks = []
        
        for line in response.iter_lines(decode_unicode=True):
            current_time = time.time()
            
            if line and line.startswith("data:"):
                chunk_count += 1
                chunk_data = json.loads(line.replace("data: ", ""))
                chunk_text = chunk_data.get("chunk", "")
                
                if chunk_text:
                    total_chars += len(chunk_text)
                    chunks.append(chunk_text)
                
                # è®°å½•ç¬¬ä¸€ä¸ªchunkæ—¶é—´
                if first_chunk_time is None and chunk_text:
                    first_chunk_time = current_time
                    first_token_latency = first_chunk_time - start_time
                    print(f"  âš¡ First Tokenå»¶è¿Ÿ:")
                    print_result("æ€»å»¶è¿Ÿ", first_token_latency)
                    print_result("ç½‘ç»œ+å¤„ç†", first_chunk_time - request_sent_time)
                    print(f"  ğŸ“Š é¦–ä¸ªchunkå†…å®¹: '{chunk_text[:50]}{'...' if len(chunk_text) > 50 else ''}'")
                    print()
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if chunk_data.get("status") == "finished":
                    last_chunk_time = current_time
                    break
        
        if first_chunk_time is None:
            raise Exception("æ²¡æœ‰æ”¶åˆ°ä»»ä½•å“åº”chunk")
        
        total_latency = last_chunk_time - start_time if last_chunk_time else time.time() - start_time
        generation_time = last_chunk_time - first_chunk_time if last_chunk_time else 0
        
        print(f"  ğŸ“Š å®Œæ•´å“åº”ç»Ÿè®¡:")
        print(f"  - æ€»chunkæ•°: {chunk_count}")
        print(f"  - æ€»å­—ç¬¦æ•°: {total_chars}")
        print_result("æ€»å“åº”æ—¶é—´", total_latency)
        if generation_time > 0:
            print_result("ç”Ÿæˆé˜¶æ®µ", generation_time)
            print(f"  - ç”Ÿæˆé€Ÿåº¦: {total_chars/generation_time:.2f} å­—ç¬¦/ç§’")
        
        print(f"\n  ğŸ’¬ å®Œæ•´å“åº”é¢„è§ˆ:")
        full_response = "".join(chunks)
        preview_length = min(300, len(full_response))
        print(f"  {full_response[:preview_length]}{'...' if len(full_response) > preview_length else ''}")
        
        # è¿”å›ç»“æœ
        return {
            'success': True,
            'first_token_latency': first_token_latency if first_chunk_time else None,
            'total_latency': total_latency,
            'chunk_count': chunk_count,
            'total_chars': total_chars,
            'generation_speed': total_chars/generation_time if generation_time > 0 else 0,
            'full_response': full_response
        }
        
    except Exception as e:
        print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {'success': False, 'error': str(e)}

def test_avatar_service_health():
    """æµ‹è¯•æ•°å­—äººæœåŠ¡å¥åº·çŠ¶æ€"""
    print_header("æ•°å­—äººæœåŠ¡å¥åº·æ£€æŸ¥")
    
    services = [
        ("Lip-syncæœåŠ¡", "http://localhost:8615/offer", "POST"),
        ("LLMæœåŠ¡", "http://localhost:8610/chat/stream", "POST"),
        ("BackendæœåŠ¡", "http://localhost:8203/api/chat/history", "GET"),
    ]
    
    results = {}
    
    for name, url, method in services:
        try:
            start = time.time()
            if method == "GET":
                resp = requests.get(url, timeout=5)
            else:
                resp = requests.post(url, json={}, timeout=5)
            latency = time.time() - start
            
            # å³ä½¿è¿”å›é”™è¯¯çŠ¶æ€ç ï¼Œåªè¦èƒ½è¿æ¥å°±ç®—æœåŠ¡åœ¨çº¿
            status = "âœ… åœ¨çº¿" if resp.status_code < 500 else "âš ï¸  æœåŠ¡é”™è¯¯"
            print(f"  {status} - {name}")
            print(f"      URL: {url}")
            print(f"      å“åº”æ—¶é—´: {latency*1000:.2f} ms")
            print(f"      çŠ¶æ€ç : {resp.status_code}")
            results[name] = {'online': True, 'latency': latency, 'status_code': resp.status_code}
        except requests.exceptions.ConnectionError:
            print(f"  âŒ ç¦»çº¿ - {name}")
            print(f"      URL: {url}")
            print(f"      é”™è¯¯: æ— æ³•è¿æ¥")
            results[name] = {'online': False, 'error': 'Connection refused'}
        except Exception as e:
            print(f"  âŒ é”™è¯¯ - {name}")
            print(f"      URL: {url}")
            print(f"      é”™è¯¯: {e}")
            results[name] = {'online': False, 'error': str(e)}
    
    return results

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\nğŸš€ æ•°å­—äººç³»ç»Ÿå»¶è¿Ÿæµ‹è¯•å·¥å…·ï¼ˆç®€åŒ–ç‰ˆï¼‰\n")
    
    # 1. æœåŠ¡å¥åº·æ£€æŸ¥
    health_results = test_avatar_service_health()
    
    # 2. First Tokenå»¶è¿Ÿæµ‹è¯•
    print("\n")
    test_questions = [
        "What is machine learning?",
        "Explain quantum computing in simple terms.",
        "Hello, how are you today?"
    ]
    
    print_header("é€‰æ‹©æµ‹è¯•åœºæ™¯")
    print("\n  å¯ç”¨çš„æµ‹è¯•é—®é¢˜:")
    for i, q in enumerate(test_questions, 1):
        print(f"    {i}. {q}")
    print(f"    {len(test_questions)+1}. è‡ªå®šä¹‰é—®é¢˜")
    
    choice = input(f"\n  è¯·é€‰æ‹© (1-{len(test_questions)+1}) [é»˜è®¤: 1]: ").strip()
    
    if not choice:
        choice = "1"
    
    if choice.isdigit() and 1 <= int(choice) <= len(test_questions):
        test_text = test_questions[int(choice)-1]
    elif choice == str(len(test_questions)+1):
        test_text = input("  è¯·è¾“å…¥æµ‹è¯•é—®é¢˜: ").strip()
        if not test_text:
            test_text = test_questions[0]
    else:
        print("  æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤é—®é¢˜")
        test_text = test_questions[0]
    
    print("\n")
    result = test_llm_first_token_latency(test_text)
    
    # 3. ä¿å­˜ç»“æœ
    if result.get('success'):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"latency_test_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'test_question': test_text,
                'health_check': health_results,
                'latency_results': result
            }, f, indent=2, ensure_ascii=False)
        
        print_header("æµ‹è¯•å®Œæˆ")
        print(f"\n  ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        print(f"  âš¡ First Tokenå»¶è¿Ÿ: {result['first_token_latency']*1000:.2f} ms")
        print(f"  ğŸ“Š ç”Ÿæˆé€Ÿåº¦: {result['generation_speed']:.2f} å­—ç¬¦/ç§’")
        print("\n" + "="*60 + "\n")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

